{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as panda\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.model_selection import learning_curve\n",
    "\n",
    "from datetime import datetime\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size:  2000\n"
     ]
    }
   ],
   "source": [
    "# completeDataset = panda.read_csv('quakes_radius300.csv')\n",
    "inputFileName = environ['inputFileName']\n",
    "completeDataset = panda.read_csv(inputFileName)\n",
    "nrRows = len(completeDataset)\n",
    "print('total data size: ', nrRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove nulls ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size:  2000\n"
     ]
    }
   ],
   "source": [
    "completeDataset = completeDataset.dropna()\n",
    "nrRows = len(completeDataset)\n",
    "print('total data size: ', nrRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format timestamp ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_date_to_number(date):\n",
    "#     date = str(date)\n",
    "#     date = date.replace('T',' ').replace('Z','+00:00')\n",
    "#     return int(datetime.fromisoformat(date).timestamp())\n",
    "\n",
    "# completeDataset['timestamp'] = completeDataset.time.apply(convert_date_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take only the necessary fields ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.6473</td>\n",
       "      <td>-74.3805</td>\n",
       "      <td>155.59</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-58.0753</td>\n",
       "      <td>-25.7163</td>\n",
       "      <td>69.39</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.1131</td>\n",
       "      <td>-69.0743</td>\n",
       "      <td>132.21</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.2029</td>\n",
       "      <td>-69.5807</td>\n",
       "      <td>152.75</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.2549</td>\n",
       "      <td>-87.7317</td>\n",
       "      <td>170.43</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude   depth  mag\n",
       "0   -8.6473   -74.3805  155.59  4.5\n",
       "1  -58.0753   -25.7163   69.39  5.0\n",
       "2  -21.1131   -69.0743  132.21  4.4\n",
       "3  -18.2029   -69.5807  152.75  5.1\n",
       "4   13.2549   -87.7317  170.43  4.6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced_dataset = completeDataset[['latitude', 'longitude', 'depth', 'mag', 'timestamp', 'rms', 'magError', 'time']].copy()\n",
    "reduced_dataset = completeDataset[['latitude', 'longitude', 'depth', 'mag']].copy()\n",
    "\n",
    "reduced_dataset.head()\n",
    "# print('train dataset: %s, test dataset %s' %(str(train_dataset_full.shape), str(test_dataset_full.shape)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounded may disturb, try multiplying\n",
    "reduced_dataset.mag = reduced_dataset.mag * 100\n",
    "# Need to round the magnitude in order to be able to compute the accuracy\n",
    "reduced_dataset.mag = panda.Series(reduced_dataset.mag).apply(round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract X_train, Y_train, X_test and Y_test ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  1999\n",
      "Validation data size:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-58.0753</td>\n",
       "      <td>-25.7163</td>\n",
       "      <td>69.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-21.1131</td>\n",
       "      <td>-69.0743</td>\n",
       "      <td>132.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.2029</td>\n",
       "      <td>-69.5807</td>\n",
       "      <td>152.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.2549</td>\n",
       "      <td>-87.7317</td>\n",
       "      <td>170.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-35.8690</td>\n",
       "      <td>-103.8833</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude   depth\n",
       "1  -58.0753   -25.7163   69.39\n",
       "2  -21.1131   -69.0743  132.21\n",
       "3  -18.2029   -69.5807  152.75\n",
       "4   13.2549   -87.7317  170.43\n",
       "5  -35.8690  -103.8833   10.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_dataset_mag=reduced_dataset['mag']\n",
    "reduced_dataset_no_mag=reduced_dataset.drop(\"mag\",axis=1)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(reduced_dataset_no_mag, reduced_dataset_mag, test_size= 0.25, random_state=42)\n",
    "X_train = reduced_dataset_no_mag.tail(nrRows-1)\n",
    "X_test = reduced_dataset_no_mag.head(1)\n",
    "Y_train = reduced_dataset_mag.tail(nrRows-1)\n",
    "Y_test =reduced_dataset_mag.head(1)\n",
    "print('Training data size: ', len(X_train))\n",
    "print('Validation data size: ', len(X_test))\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(df):\n",
    "#     low = .0\n",
    "#     high = 1.0\n",
    "#     quant_df = df.quantile([low, high])\n",
    "#     for name in list(df.columns):\n",
    "#       if is_numeric_dtype(df[name]):\n",
    "#        df = df[(df[name] > quant_df.loc[low, name]) \n",
    "#                & (df[name] < quant_df.loc[high, name])]\n",
    "#     return df\n",
    "\n",
    "# X_train = remove_outliers(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2]\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=300,class_weight='balanced',n_jobs=2,random_state=42)\n",
    "rf.fit(X_train,Y_train)\n",
    "# acc=rf.score(X_test,Y_test)\n",
    "# print(acc)\n",
    "pred = []\n",
    "pred.append(rf.predict(X_test)/100)\n",
    "print(pred[0])\n",
    "# acc2=accuracy_score(Y_test, pred)\n",
    "# print(acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without scaling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50,50,50,50,50 ), max_iter=500, alpha=0.0001, solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "mlp.fit(X_train, Y_train)\n",
    "# acc = mlp.score(X_test, Y_test)\n",
    "# print(acc)\n",
    "pred.append(mlp.predict(X_test)/100)\n",
    "print(pred[1])\n",
    "# acc2 = accuracy_score(Y_test, pred)\n",
    "# print(acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With scaling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler() \n",
    "scaler.fit(X_train)  \n",
    "X_train_scaled = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train_scaled, Y_train)\n",
    "# acc = mlp.score(X_test_scaled, Y_test)\n",
    "# print(acc)\n",
    "pred.append(mlp.predict(X_test_scaled)/100)\n",
    "print(pred[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors Plot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sizes, train_scores, validation_scores = learning_curve(\n",
    "#     estimator = mlp,\n",
    "#     X = X_train,\n",
    "#     y = Y_train,\n",
    "#     train_sizes = [1, 100, 500, 2000, 5000, 6152],\n",
    "#     cv = 2,\n",
    "#     scoring = 'neg_mean_squared_error'\n",
    "# )\n",
    "# train_scores_mean = -train_scores.mean(axis = 1)\n",
    "# validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "# plt.style.use('seaborn')\n",
    "# plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "# plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "# plt.ylabel('RFC', fontsize = 14)\n",
    "# plt.xlabel('Training set size', fontsize = 14)\n",
    "# plt.legend()\n",
    "# plt.ylim(0,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto') #(C=0.1, penalty='l1', tol=1e-6)\n",
    "logreg.fit(X_train, Y_train)\n",
    "pred.append(logreg.predict(X_test)/100)\n",
    "print(pred[3])\n",
    "# acc = logreg.score(X_test, Y_test)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C = 0.1, gamma=0.1)\n",
    "svc.fit(X_train, Y_train)\n",
    "\n",
    "# acc = svc.score(X_test, Y_test)\n",
    "# print(acc)\n",
    "pred.append(svc.predict(X_test)/100)\n",
    "print(pred[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    criterion='entropy',\n",
    "    max_depth=11,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    bootstrap=False,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "# acc = random_forest.score(X_test, Y_test)\n",
    "# print(acc)\n",
    "pred.append(random_forest.predict(X_test)/100)\n",
    "print(pred[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.csv', 'w') as csvfile:\n",
    "  w = csv.writer(csvfile)\n",
    "  w.writerow([\"Prediction\"])\n",
    "\n",
    "  for i in range(len(pred)):\n",
    "    w.writerow(pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
