{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as panda\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.model_selection import learning_curve\n",
    "\n",
    "from datetime import datetime\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size:  2000\n"
     ]
    }
   ],
   "source": [
    "inputFileName = environ['inputFileName']\n",
    "# inputFileName = 'quakes_radius1000.csv'\n",
    "completeDataset = panda.read_csv(inputFileName)\n",
    "nrRows = len(completeDataset)\n",
    "print('total data size: ', nrRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove nulls ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size:  2000\n"
     ]
    }
   ],
   "source": [
    "completeDataset = completeDataset.dropna()\n",
    "nrRows = len(completeDataset)\n",
    "print('total data size: ', nrRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format timestamp ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_date_to_number(date):\n",
    "#     date = str(date)\n",
    "#     date = date.replace('T',' ').replace('Z','+00:00')\n",
    "#     return int(datetime.fromisoformat(date).timestamp())\n",
    "\n",
    "# completeDataset['timestamp'] = completeDataset.time.apply(convert_date_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take only the necessary fields ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-27.6846</td>\n",
       "      <td>-67.9473</td>\n",
       "      <td>132.73</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.6300</td>\n",
       "      <td>-71.4315</td>\n",
       "      <td>44.75</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-24.0340</td>\n",
       "      <td>-66.9969</td>\n",
       "      <td>168.16</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-24.0112</td>\n",
       "      <td>-66.9300</td>\n",
       "      <td>164.35</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-24.1014</td>\n",
       "      <td>-66.7737</td>\n",
       "      <td>213.97</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude   depth  mag\n",
       "0  -27.6846   -67.9473  132.73  4.6\n",
       "1  -30.6300   -71.4315   44.75  4.2\n",
       "2  -24.0340   -66.9969  168.16  4.8\n",
       "3  -24.0112   -66.9300  164.35  5.4\n",
       "4  -24.1014   -66.7737  213.97  4.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduced_dataset = completeDataset[['latitude', 'longitude', 'depth', 'mag', 'timestamp', 'rms', 'magError', 'time']].copy()\n",
    "reduced_dataset = completeDataset[['latitude', 'longitude', 'depth', 'mag']].copy()\n",
    "\n",
    "reduced_dataset.head()\n",
    "# print('train dataset: %s, test dataset %s' %(str(train_dataset_full.shape), str(test_dataset_full.shape)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounded may disturb, try multiplying\n",
    "reduced_dataset.mag = reduced_dataset.mag * 100\n",
    "# Need to round the magnitude in order to be able to compute the accuracy\n",
    "reduced_dataset.mag = panda.Series(reduced_dataset.mag).apply(round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract X_train, Y_train, X_test and Y_test ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  1999\n",
      "Validation data size:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.6300</td>\n",
       "      <td>-71.4315</td>\n",
       "      <td>44.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-24.0340</td>\n",
       "      <td>-66.9969</td>\n",
       "      <td>168.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-24.0112</td>\n",
       "      <td>-66.9300</td>\n",
       "      <td>164.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-24.1014</td>\n",
       "      <td>-66.7737</td>\n",
       "      <td>213.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-24.2461</td>\n",
       "      <td>-67.3871</td>\n",
       "      <td>207.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude   depth\n",
       "1  -30.6300   -71.4315   44.75\n",
       "2  -24.0340   -66.9969  168.16\n",
       "3  -24.0112   -66.9300  164.35\n",
       "4  -24.1014   -66.7737  213.97\n",
       "5  -24.2461   -67.3871  207.10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_dataset_mag=reduced_dataset['mag']\n",
    "reduced_dataset_no_mag=reduced_dataset.drop(\"mag\",axis=1)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(reduced_dataset_no_mag, reduced_dataset_mag, test_size= 0.25, random_state=42)\n",
    "X_train = reduced_dataset_no_mag.tail(nrRows-1)\n",
    "X_test = reduced_dataset_no_mag.head(1)\n",
    "Y_train = reduced_dataset_mag.tail(nrRows-1)\n",
    "Y_test =reduced_dataset_mag.head(1)\n",
    "print('Training data size: ', len(X_train))\n",
    "print('Validation data size: ', len(X_test))\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(df):\n",
    "#     low = .0\n",
    "#     high = 1.0\n",
    "#     quant_df = df.quantile([low, high])\n",
    "#     for name in list(df.columns):\n",
    "#       if is_numeric_dtype(df[name]):\n",
    "#        df = df[(df[name] > quant_df.loc[low, name]) \n",
    "#                & (df[name] < quant_df.loc[high, name])]\n",
    "#     return df\n",
    "\n",
    "# X_train = remove_outliers(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [-1,-1,-1,-1,-1,-1,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4]\n"
     ]
    }
   ],
   "source": [
    "# rf=RandomForestClassifier(n_estimators=300,class_weight='balanced',n_jobs=2,random_state=42)\n",
    "# rf.fit(X_train,Y_train)\n",
    "# # acc=rf.score(X_test,Y_test)\n",
    "# # print(acc)\n",
    "# pred = [-1,-1,-1,-1,-1,-1,-1]\n",
    "# pred[0] = rf.predict(X_test)/100\n",
    "# print(pred[0])\n",
    "# # acc2=accuracy_score(Y_test, pred)\n",
    "# # print(acc2)\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    criterion='entropy',\n",
    "    max_depth=11,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    bootstrap=False,\n",
    "    oob_score=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "# acc = random_forest.score(X_test, Y_test)\n",
    "# print(acc)\n",
    "pred[0] = random_forest.predict(X_test)/100\n",
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without scaling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50,50,50,50,50 ), max_iter=500, alpha=0.0001, solver='sgd', verbose=0,  random_state=42,tol=0.000000001)\n",
    "mlp.fit(X_train, Y_train)\n",
    "# acc = mlp.score(X_test, Y_test)\n",
    "# print(acc)\n",
    "pred[1] = mlp.predict(X_test)/100\n",
    "print(pred[1])\n",
    "# acc2 = accuracy_score(Y_test, pred)\n",
    "# print(acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With scaling ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler() \n",
    "scaler.fit(X_train)  \n",
    "X_train_scaled = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train_scaled, Y_train)\n",
    "# acc = mlp.score(X_test_scaled, Y_test)\n",
    "# print(acc)\n",
    "pred[2] = mlp.predict(X_test_scaled)/100\n",
    "print(pred[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors Plot ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sizes, train_scores, validation_scores = learning_curve(\n",
    "#     estimator = mlp,\n",
    "#     X = X_train,\n",
    "#     y = Y_train,\n",
    "#     train_sizes = [1, 100, 500, 2000, 5000, 6152],\n",
    "#     cv = 2,\n",
    "#     scoring = 'neg_mean_squared_error'\n",
    "# )\n",
    "# train_scores_mean = -train_scores.mean(axis = 1)\n",
    "# validation_scores_mean = -validation_scores.mean(axis = 1)\n",
    "# plt.style.use('seaborn')\n",
    "# plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "# plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "# plt.ylabel('RFC', fontsize = 14)\n",
    "# plt.xlabel('Training set size', fontsize = 14)\n",
    "# plt.legend()\n",
    "# plt.ylim(0,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto') #(C=0.1, penalty='l1', tol=1e-6)\n",
    "logreg.fit(X_train, Y_train)\n",
    "pred[3] = logreg.predict(X_test)/100\n",
    "print(pred[3])\n",
    "# acc = logreg.score(X_test, Y_test)\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3]\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C = 0.1, gamma=0.1)\n",
    "svc.fit(X_train, Y_train)\n",
    "\n",
    "# acc = svc.score(X_test, Y_test)\n",
    "# print(acc)\n",
    "pred[4] = svc.predict(X_test)/100\n",
    "print(pred[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.csv', 'a+') as csvfile:\n",
    "  w = csv.writer(csvfile)\n",
    " # real magnitude, file, output\n",
    "  radius = re.search('quakes_radius(.*?).csv', inputFileName).group(1)\n",
    "  w.writerow([radius, Y_test[0]/100, pred[0][0], pred[1][0], pred[2][0], pred[3][0], pred[4][0]])\n",
    "\n",
    "#   for i in range(len(pred)):\n",
    "#     w.writerow(pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
